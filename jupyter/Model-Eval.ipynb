{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InThe episode begins with Timothy telling Wesley and Gagarin that the planet is in danger, but then the two are interrupted by the apparent destruction of a weapons platforms sent out to intercept the Federation fleet. Wesley and Gagarin rush to the platforms\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
    "configuration.max_length = 1024\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "gen = pipeline('text-generation',model='./my_model', tokenizer=tokenizer,config=configuration)\n",
    "\n",
    "result = gen('In')[0]['generated_text']\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "configuration.vocab_size = 50259\n",
    "import re\n",
    "\n",
    "\n",
    "alphabets= \"([A-Za-z])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr|Lt)[.]\"\n",
    "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "websites = \"[.](com|net|org|io|gov)\"\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = sentences[:-1]\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    return sentences\n",
    "\n",
    "def next_line(s):\n",
    "    input_ids = tokenizer.encode(s, return_tensors='pt')\n",
    "    model = GPT2LMHeadModel.from_pretrained(\"./my_model\", config=configuration)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    sample_outputs = model.generate(\n",
    "                                input_ids,\n",
    "                                do_sample=True,   \n",
    "                                top_k=50, \n",
    "                                max_length = 800,\n",
    "                                top_p=0.95, \n",
    "                                num_return_sequences=1\n",
    "                        )\n",
    "    return [(i, tokenizer.decode(sample_output, skip_special_tokens=True)) for i, sample_output in enumerate(sample_outputs)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_acts(seed_s, min_acts= 3, prior_acts=[]):\n",
    "    o = next_line(seed_s)\n",
    "    acts = [next_line(s)[0][1] for s in split_into_sentences(o[0][1])]\n",
    "    if len(acts) < min_acts:\n",
    "        acts = [make_acts(a, min_acts= 2) for a in acts]\n",
    "    else:\n",
    "        return acts\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Klingons have recently been transmitting messages of glee and whimsy to the Federation. Worf suggests that the Federation can intervene, by sending representatives from a number of non-Federation states. Riker advises that he cannot interfere with a Federation civil government, which he sees as dangerous. Riker then states that while the Federation might be good, it is not ideal for Starfleet and he believes that \"any interference is welcome.\" Riker sends for advice from his ship's navigational systems, but they are unable to correct their warp engines. Although the Enterprise approaches the warbirds, and despite the advice that one star, the Enterprise approaches a star that is half obscured by the cloak, and the Enterprise is caught in the star's atmosphere, the ship has traveled over 285,000 kilometers before the warbirds have gone. This is the first time that the ship had traveled over 285,000 kilometers before the Enterprise. Riker is told that if he is able to correct his ship's navigational systems, Starfleet will help to save the Federation. Riker is ordered to escort the Enterprise to the Starbase, but his double is unable to transport him. Riker and Riker return to the Starbase, and the Enterprise continues to the Starbase. At night, Dax, the Klingons' second-in-command, is able to free herself by changing the frequency of the Enterprise's warp engine, but then is captured by Commander Riker, revealing that the ship has already traveled over 285,000 kilometers.\n",
      "----\n",
      "At this point, Sisko is having the fun of playing the game. He asks Quark and Odo to take him through each level (with Sisko able to open up to Quark about his goals) and helps them interact in a manner that helps them solve the puzzle. Quark suggests linking them with the game to try to learn more about how it would work.\n",
      "----\n",
      "However, as the game progresses, Picard becomes increasingly irritable and irritable, and he becomes irritated when the game gets too-oriented for him. Eventually, he becomes overly eager to play and plays games. Playing the game would make him a lousy captain, and he realizes he is playing into the role of poker. When he walks out, his pride and jealousy at first grow and he realizes he has lost sight of poker for a long time. He decides to quit the game, and instead joins the crew.\n",
      "----\n",
      "He decides to play the game as a distraction in a final attempt to win the confidence of the Klingons, so that their morale and morale will be damaged. They kill Dax and take the cargo bay. Dax and Worf return to the runabout, where they discover that the ship had been destroyed by Klingon weapons fire, and the crew is dead. Dax and Worf are rescued from the planet by Captain Jean-Luc Picard. Worf is put in charge of Dax's team. Picard assigns her to be acting head of security; Dax is responsible for overseeing security and expects that the crew will be in complete control of the ship.\n",
      "----\n",
      "Picard is tempted to quit, and if the game does not succeed, he will be put in the untenable situation that they have always been in, which might result in the Klingon victory. As it happens, Worf is only able to use the transporter, however he does not have much time to explain to La Forge and Dax what is going on.\n"
     ]
    }
   ],
   "source": [
    "seed_s = \"The Klingons have recently been transmitting messages of glee and whimsy\"\n",
    "\n",
    "acts = make_acts(seed_s)\n",
    "print(\"\\n----\\n\".join(acts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": true,
   "docker_image": "gcr.io/arrikto/jupyter-kale-py36@sha256:dd3f92ca66b46d247e4b9b6a9d84ffbb368646263c2e3909473c3b851f3fe198",
   "experiment": {
    "id": "new",
    "name": "test2"
   },
   "experiment_name": "test2",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "baz",
   "pipeline_name": "foo1",
   "snapshot_volumes": true,
   "steps_defaults": [
    "label:access-ml-pipeline:true",
    "label:access-rok:true"
   ],
   "volume_access_mode": "rwm",
   "volumes": [
    {
     "annotations": [],
     "mount_point": "/home/jovyan",
     "name": "foo1-fwhrc-nb-server1-workspace-95jz4-8k6hj",
     "size": 5,
     "size_type": "Gi",
     "snapshot": false,
     "type": "clone"
    }
   ]
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
